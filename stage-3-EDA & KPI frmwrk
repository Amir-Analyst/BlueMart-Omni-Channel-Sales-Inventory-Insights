# ===============================================================
# ğŸ“˜ BLUEMART PROJECT â€” STAGE 3: EXPLORATORY DATA ANALYSIS & KPI FRAMEWORK
# Author: Amir
# ===============================================================

# -------------------------------
# 1ï¸âƒ£ Setup
# -------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from matplotlib.ticker import FuncFormatter
from datetime import datetime

# Mount Drive (if on Colab)
from google.colab import drive
drive.mount('/content/drive')

# -------------------------------
# 2ï¸âƒ£ File Paths & Config
# -------------------------------
BASE_PATH = "/content/drive/MyDrive/Amir/work/Data Science/project/dataset/bluemart"
INPUT_PATH = f"{BASE_PATH}/processed"
OUTPUT_PATH = f"{BASE_PATH}/analysis"

os.makedirs(OUTPUT_PATH, exist_ok=True)
INSIGHT_LOG = f"{OUTPUT_PATH}/insight_log.csv"

# -------------------------------
# 3ï¸âƒ£ Load Clean Unified Dataset
# -------------------------------
df = pd.read_csv(f"{INPUT_PATH}/sales_enriched.csv", parse_dates=["date"])
df.rename(columns={"date": "txn_date"}, inplace=True)

print("âœ… Data loaded successfully. Shape:", df.shape)

# -------------------------------
# 4ï¸âƒ£ Utility: Insight Logger
# -------------------------------
def log_insight(category, insight_text):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    entry = pd.DataFrame([[ts, category, insight_text]], 
                         columns=["timestamp", "category", "insight"])
    if os.path.exists(INSIGHT_LOG):
        entry.to_csv(INSIGHT_LOG, mode="a", index=False, header=False)
    else:
        entry.to_csv(INSIGHT_LOG, index=False)
    print(f"ğŸ§  Logged insight â†’ [{category}] {insight_text}")

# -------------------------------
# 5ï¸âƒ£ Human-Readable Formatters
# -------------------------------
def human_format(num):
    units = ['', 'K', 'M', 'B', 'T']
    magnitude = 0
    num = float(num)
    while abs(num) >= 1000 and magnitude < len(units) - 1:
        magnitude += 1
        num /= 1000.0
    return f"{num:.1f}{units[magnitude]}"

def axis_formatter(x, pos):
    return human_format(x)

def add_value_labels(ax, horizontal=False):
    """Adds human-readable value labels to bars."""
    for p in ax.patches:
        value = p.get_width() if horizontal else p.get_height()
        if horizontal:
            ax.text(
                value + value*0.01, p.get_y() + p.get_height()/2,
                human_format(value),
                va='center', ha='left', fontsize=9
            )
        else:
            ax.text(
                p.get_x() + p.get_width()/2, value + value*0.01,
                human_format(value),
                ha='center', va='bottom', fontsize=9
            )

# -------------------------------
# 6ï¸âƒ£ Data Quality Snapshot
# -------------------------------
missing_summary = df.isna().mean().sort_values(ascending=False)
log_insight("Data Quality", f"Top missing columns: {missing_summary.head(5).to_dict()}")

dup_count = df.duplicated().sum()
log_insight("Data Quality", f"Duplicate rows detected: {dup_count}")

# -------------------------------
# 7ï¸âƒ£ BASIC KPI COMPUTATION (Option B)
# -------------------------------
total_revenue = df["revenue"].sum()
total_profit = df["profit"].sum()
avg_basket_size = df["quantity"].mean()
avg_order_value = df["revenue"].mean()
customer_count = df["customer_id"].nunique()
repeat_pct = df.groupby("customer_id")["receipt_id"].nunique().gt(1).mean() * 100

kpi_df = pd.DataFrame({
    "metric": [
        "Total Revenue",
        "Total Profit",
        "Avg Basket Size",
        "Avg Order Value",
        "Customer Count",
        "Repeat Purchase Share (%)"
    ],
    "value": [
        total_revenue,
        total_profit,
        avg_basket_size,
        avg_order_value,
        customer_count,
        repeat_pct
    ]
})

# Convert KPI values to human-readable
kpi_df["value"] = kpi_df.apply(
    lambda row: f"{human_format(row['value'])}%" if "Share" in row['metric'] else human_format(row['value']),
    axis=1
)

print("\nğŸ“Š KPI Summary:")
display(kpi_df)
log_insight("KPIs", f"Total revenue={human_format(total_revenue)}, repeat shoppers={repeat_pct:.1f}%")

# -------------------------------
# 8ï¸âƒ£ Daily Revenue Trend
# -------------------------------
daily = df.groupby("txn_date", as_index=False)["revenue"].sum()
plt.figure(figsize=(14, 5))
plt.plot(daily["txn_date"], daily["revenue"], linewidth=2, color="#005f73", marker='o', markersize=3)

peak_idx = daily["revenue"].idxmax()
peak_date = daily.loc[peak_idx, "txn_date"]
peak_value = daily.loc[peak_idx, "revenue"]
plt.scatter(peak_date, peak_value, color="#0a9396", s=80, zorder=5)
plt.text(peak_date, peak_value * 1.03, f"Peak: {human_format(peak_value)}", fontsize=10)

plt.gca().yaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.title("Daily Revenue Trend â€” 2025", fontsize=14, color="#005f73")
plt.xlabel("Date")
plt.ylabel("Revenue")
plt.xticks(rotation=45)
plt.grid(alpha=0.25)
plt.tight_layout()
plt.show()
log_insight("Trend", f"Peak daily revenue: {human_format(peak_value)} on {peak_date}")

# -------------------------------
# 9ï¸âƒ£ Segment Profiling â€” Data Preparation
# -------------------------------
channel_rev = df.groupby("channel", as_index=False)["revenue"].sum()
top_stores = df.groupby("store_name")["revenue"].sum().nlargest(10)
category_rev = df.groupby("category")["revenue"].sum().sort_values(ascending=False)
cust_seg = df.groupby("loyalty_segment")["revenue"].sum().sort_values(ascending=False)

# Bluemart Color Palette
palette_primary = ["#005f73", "#0a9396", "#94d2bd"]

# -------------------------------
# ğŸ”Ÿ Segment Profiling â€” Charts
# -------------------------------
# CHANNEL MIX
plt.figure(figsize=(8,5))
ax = sns.barplot(data=channel_rev, x="channel", y="revenue", palette=palette_primary)
add_value_labels(ax)
ax.yaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.xticks(rotation=20)
plt.title("Revenue by Channel")
plt.tight_layout()
plt.show()

# TOP STORES
plt.figure(figsize=(10,5))
ax = top_stores.plot(kind="bar", color="#0a9396")
add_value_labels(ax)
ax.yaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.xticks(rotation=45)
plt.title("Top 10 Stores by Revenue")
plt.tight_layout()
plt.show()

# CATEGORY MIX
plt.figure(figsize=(10,6))
top_cat = category_rev.head(10).sort_values()
ax = top_cat.plot(kind="barh", color="#005f73")
add_value_labels(ax, horizontal=True)
ax.xaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.title("Top 10 Categories by Revenue")
plt.tight_layout()
plt.show()

# CUSTOMER SEGMENTS
plt.figure(figsize=(8,5))
ax = cust_seg.plot(kind="bar", color="#94d2bd")
add_value_labels(ax)
ax.yaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.xticks(rotation=25)
plt.title("Revenue by Customer Loyalty Segment")
plt.tight_layout()
plt.show()

# -------------------------------
# 1ï¸âƒ£1ï¸âƒ£ Promotion Impact
# -------------------------------
if "is_discounted" not in df.columns:
    df["is_discounted"] = df["promo_id"].notna()

plt.figure(figsize=(8,5))
sns.boxplot(
    data=df,
    x="is_discounted",
    y="revenue",
    palette=["#005f73", "#0a9396"]
)
plt.gca().yaxis.set_major_formatter(FuncFormatter(axis_formatter))
plt.title("Revenue Distribution â€” Discount vs Non-Discount", fontsize=14)
plt.xlabel("Discount Applied (0 = No, 1 = Yes)")
plt.ylabel("Revenue")
plt.tight_layout()
plt.show()

# -------------------------------
# 1ï¸âƒ£2ï¸âƒ£ Save Artifacts
# -------------------------------
kpi_df.to_csv(f"{OUTPUT_PATH}/kpi_summary.csv", index=False)
channel_rev.to_csv(f"{OUTPUT_PATH}/channel_mix.csv", index=False)
category_rev.to_csv(f"{OUTPUT_PATH}/category_mix.csv")
cust_seg.to_csv(f"{OUTPUT_PATH}/customer_segment_rev.csv")
daily.to_csv(f"{OUTPUT_PATH}/daily_revenue.csv", index=False)

print("âœ… Outputs saved successfully â†’", OUTPUT_PATH)

# -------------------------------
# 1ï¸âƒ£3ï¸âƒ£ Next Step Preview
# -------------------------------
print("""
ğŸš€ Next Stage (Stage 4): Dashboard Modeling & KPI Visualization
- Power BI Dashboard
- Streamlit Sales Monitoring App
- Automated Weekly Performance Report
""")

